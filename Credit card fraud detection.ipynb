{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# CREDIT CARD FRAUD DETECTION"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ".\n## Problem statement:-<br>\nThe aim of the project is to predict fraudulent credit card transactions using machine learning models. This is crucial from the bank\u2019s as well as customer\u2019s perspective. The banks cannot afford to lose their customers\u2019 money to fraudsters. Every fraud is a loss to the bank as the bank is responsible for the fraud transactions.\n\nThe dataset contains transactions made over a period of two days in September 2013 by European credit cardholders. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. We need to take care of the data imbalance while building the model and come up with the best model by trying various algorithms.\n\nSteps:-\nThe steps are broadly divided into below steps. <br>\n\n - Reading, understanding and visualising the data<br>\n - Preparing the data for modelling<br>\n - Building the model<br>\n - Evaluate the model"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n# Importing libraries for cross validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 31 columns</p>\n</div>",
                        "text/plain": "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>284802</th>\n      <td>172786.0</td>\n      <td>-11.881118</td>\n      <td>10.071785</td>\n      <td>-9.834783</td>\n      <td>-2.066656</td>\n      <td>-5.364473</td>\n      <td>-2.606837</td>\n      <td>-4.918215</td>\n      <td>7.305334</td>\n      <td>1.914428</td>\n      <td>...</td>\n      <td>0.213454</td>\n      <td>0.111864</td>\n      <td>1.014480</td>\n      <td>-0.509348</td>\n      <td>1.436807</td>\n      <td>0.250034</td>\n      <td>0.943651</td>\n      <td>0.823731</td>\n      <td>0.77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284803</th>\n      <td>172787.0</td>\n      <td>-0.732789</td>\n      <td>-0.055080</td>\n      <td>2.035030</td>\n      <td>-0.738589</td>\n      <td>0.868229</td>\n      <td>1.058415</td>\n      <td>0.024330</td>\n      <td>0.294869</td>\n      <td>0.584800</td>\n      <td>...</td>\n      <td>0.214205</td>\n      <td>0.924384</td>\n      <td>0.012463</td>\n      <td>-1.016226</td>\n      <td>-0.606624</td>\n      <td>-0.395255</td>\n      <td>0.068472</td>\n      <td>-0.053527</td>\n      <td>24.79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284804</th>\n      <td>172788.0</td>\n      <td>1.919565</td>\n      <td>-0.301254</td>\n      <td>-3.249640</td>\n      <td>-0.557828</td>\n      <td>2.630515</td>\n      <td>3.031260</td>\n      <td>-0.296827</td>\n      <td>0.708417</td>\n      <td>0.432454</td>\n      <td>...</td>\n      <td>0.232045</td>\n      <td>0.578229</td>\n      <td>-0.037501</td>\n      <td>0.640134</td>\n      <td>0.265745</td>\n      <td>-0.087371</td>\n      <td>0.004455</td>\n      <td>-0.026561</td>\n      <td>67.88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284805</th>\n      <td>172788.0</td>\n      <td>-0.240440</td>\n      <td>0.530483</td>\n      <td>0.702510</td>\n      <td>0.689799</td>\n      <td>-0.377961</td>\n      <td>0.623708</td>\n      <td>-0.686180</td>\n      <td>0.679145</td>\n      <td>0.392087</td>\n      <td>...</td>\n      <td>0.265245</td>\n      <td>0.800049</td>\n      <td>-0.163298</td>\n      <td>0.123205</td>\n      <td>-0.569159</td>\n      <td>0.546668</td>\n      <td>0.108821</td>\n      <td>0.104533</td>\n      <td>10.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284806</th>\n      <td>172792.0</td>\n      <td>-0.533413</td>\n      <td>-0.189733</td>\n      <td>0.703337</td>\n      <td>-0.506271</td>\n      <td>-0.012546</td>\n      <td>-0.649617</td>\n      <td>1.577006</td>\n      <td>-0.414650</td>\n      <td>0.486180</td>\n      <td>...</td>\n      <td>0.261057</td>\n      <td>0.643078</td>\n      <td>0.376777</td>\n      <td>0.008797</td>\n      <td>-0.473649</td>\n      <td>-0.818267</td>\n      <td>-0.002415</td>\n      <td>0.013649</td>\n      <td>217.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 31 columns</p>\n</div>",
                        "text/plain": "            Time         V1         V2        V3        V4        V5  \\\n284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n\n              V6        V7        V8        V9  ...       V21       V22  \\\n284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n\n             V23       V24       V25       V26       V27       V28  Amount  \\\n284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n\n        Class  \n284802      0  \n284803      0  \n284804      0  \n284805      0  \n284806      0  \n\n[5 rows x 31 columns]"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n"
                }
            ],
            "source": "# dataset informations\ndf.info()"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Time      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.isnull().sum()"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0    284315\n1       492\nName: Class, dtype: int64"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# distribution of legit transactions & fraudulent transactions\ndf['Class'].value_counts()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This Dataset is highly unblanced<br>\n\n0 --> Normal Transaction<br>\n\n1 --> fraudulent transaction"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# separating the data for analysis\nlegit = df[df.Class == 0]\nfraud = df[df.Class == 1]"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(284315, 31)\n(492, 31)\n"
                }
            ],
            "source": "print(legit.shape)\nprint(fraud.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "count    284315.000000\nmean         88.291022\nstd         250.105092\nmin           0.000000\n25%           5.650000\n50%          22.000000\n75%          77.050000\nmax       25691.160000\nName: Amount, dtype: float64"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# statistical measures of the data\nlegit.Amount.describe()"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "count     492.000000\nmean      122.211321\nstd       256.683288\nmin         0.000000\n25%         1.000000\n50%         9.250000\n75%       105.890000\nmax      2125.870000\nName: Amount, dtype: float64"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "fraud.Amount.describe()"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>94838.202258</td>\n      <td>0.008258</td>\n      <td>-0.006271</td>\n      <td>0.012171</td>\n      <td>-0.007860</td>\n      <td>0.005453</td>\n      <td>0.002419</td>\n      <td>0.009637</td>\n      <td>-0.000987</td>\n      <td>0.004467</td>\n      <td>...</td>\n      <td>-0.000644</td>\n      <td>-0.001235</td>\n      <td>-0.000024</td>\n      <td>0.000070</td>\n      <td>0.000182</td>\n      <td>-0.000072</td>\n      <td>-0.000089</td>\n      <td>-0.000295</td>\n      <td>-0.000131</td>\n      <td>88.291022</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80746.806911</td>\n      <td>-4.771948</td>\n      <td>3.623778</td>\n      <td>-7.033281</td>\n      <td>4.542029</td>\n      <td>-3.151225</td>\n      <td>-1.397737</td>\n      <td>-5.568731</td>\n      <td>0.570636</td>\n      <td>-2.581123</td>\n      <td>...</td>\n      <td>0.372319</td>\n      <td>0.713588</td>\n      <td>0.014049</td>\n      <td>-0.040308</td>\n      <td>-0.105130</td>\n      <td>0.041449</td>\n      <td>0.051648</td>\n      <td>0.170575</td>\n      <td>0.075667</td>\n      <td>122.211321</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 30 columns</p>\n</div>",
                        "text/plain": "               Time        V1        V2        V3        V4        V5  \\\nClass                                                                   \n0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n\n             V6        V7        V8        V9  ...       V20       V21  \\\nClass                                          ...                       \n0      0.002419  0.009637 -0.000987  0.004467  ... -0.000644 -0.001235   \n1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n\n            V22       V23       V24       V25       V26       V27       V28  \\\nClass                                                                         \n0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n\n           Amount  \nClass              \n0       88.291022  \n1      122.211321  \n\n[2 rows x 30 columns]"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# compare the values for both transactions\ndf.groupby('Class').mean()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Under-Sampling<br>\n\nBuild a sample dataset containing similar distribution of normal transactions and Fraudulent Transactions<br>\n\nNumber of Fraudulent Transactions --> 492"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "legit_sample = legit.sample(n=492)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Concatenating two DataFrames"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "new_dataset = pd.concat([legit_sample, fraud], axis=0)"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>153284</th>\n      <td>98434.0</td>\n      <td>-0.144237</td>\n      <td>1.135362</td>\n      <td>-0.626225</td>\n      <td>-0.740062</td>\n      <td>1.411182</td>\n      <td>-1.081161</td>\n      <td>1.630891</td>\n      <td>-0.624599</td>\n      <td>1.280385</td>\n      <td>...</td>\n      <td>-0.044227</td>\n      <td>0.572742</td>\n      <td>-0.180005</td>\n      <td>0.740471</td>\n      <td>-0.470440</td>\n      <td>0.566064</td>\n      <td>0.277957</td>\n      <td>0.116666</td>\n      <td>11.90</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27088</th>\n      <td>34380.0</td>\n      <td>-1.596365</td>\n      <td>-0.600011</td>\n      <td>-0.657045</td>\n      <td>-1.651893</td>\n      <td>-1.541419</td>\n      <td>-0.123707</td>\n      <td>2.517731</td>\n      <td>0.164091</td>\n      <td>0.258792</td>\n      <td>...</td>\n      <td>0.483879</td>\n      <td>0.585999</td>\n      <td>1.100304</td>\n      <td>-0.032292</td>\n      <td>0.199587</td>\n      <td>-0.832829</td>\n      <td>0.119214</td>\n      <td>0.206759</td>\n      <td>560.84</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51482</th>\n      <td>44969.0</td>\n      <td>1.025895</td>\n      <td>-0.852644</td>\n      <td>0.621058</td>\n      <td>0.102443</td>\n      <td>-0.829226</td>\n      <td>0.561654</td>\n      <td>-0.699979</td>\n      <td>0.293727</td>\n      <td>1.449421</td>\n      <td>...</td>\n      <td>-0.213816</td>\n      <td>-0.615626</td>\n      <td>-0.069581</td>\n      <td>-0.723647</td>\n      <td>0.091818</td>\n      <td>1.017875</td>\n      <td>-0.046565</td>\n      <td>0.017560</td>\n      <td>112.18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>187036</th>\n      <td>127358.0</td>\n      <td>-1.489784</td>\n      <td>1.214366</td>\n      <td>2.973301</td>\n      <td>4.327308</td>\n      <td>-0.446083</td>\n      <td>1.042891</td>\n      <td>-0.392379</td>\n      <td>0.315488</td>\n      <td>-0.303154</td>\n      <td>...</td>\n      <td>-0.061712</td>\n      <td>0.668810</td>\n      <td>0.008429</td>\n      <td>-0.000273</td>\n      <td>0.156483</td>\n      <td>0.573231</td>\n      <td>0.674625</td>\n      <td>0.074159</td>\n      <td>10.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>242928</th>\n      <td>151721.0</td>\n      <td>1.775490</td>\n      <td>-1.314253</td>\n      <td>-1.444482</td>\n      <td>-0.139427</td>\n      <td>-0.629854</td>\n      <td>-0.322483</td>\n      <td>-0.292384</td>\n      <td>-0.089299</td>\n      <td>-0.566676</td>\n      <td>...</td>\n      <td>-0.082378</td>\n      <td>-0.107135</td>\n      <td>0.020498</td>\n      <td>0.757645</td>\n      <td>-0.130722</td>\n      <td>0.385287</td>\n      <td>-0.081673</td>\n      <td>-0.033003</td>\n      <td>188.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 31 columns</p>\n</div>",
                        "text/plain": "            Time        V1        V2        V3        V4        V5        V6  \\\n153284   98434.0 -0.144237  1.135362 -0.626225 -0.740062  1.411182 -1.081161   \n27088    34380.0 -1.596365 -0.600011 -0.657045 -1.651893 -1.541419 -0.123707   \n51482    44969.0  1.025895 -0.852644  0.621058  0.102443 -0.829226  0.561654   \n187036  127358.0 -1.489784  1.214366  2.973301  4.327308 -0.446083  1.042891   \n242928  151721.0  1.775490 -1.314253 -1.444482 -0.139427 -0.629854 -0.322483   \n\n              V7        V8        V9  ...       V21       V22       V23  \\\n153284  1.630891 -0.624599  1.280385  ... -0.044227  0.572742 -0.180005   \n27088   2.517731  0.164091  0.258792  ...  0.483879  0.585999  1.100304   \n51482  -0.699979  0.293727  1.449421  ... -0.213816 -0.615626 -0.069581   \n187036 -0.392379  0.315488 -0.303154  ... -0.061712  0.668810  0.008429   \n242928 -0.292384 -0.089299 -0.566676  ... -0.082378 -0.107135  0.020498   \n\n             V24       V25       V26       V27       V28  Amount  Class  \n153284  0.740471 -0.470440  0.566064  0.277957  0.116666   11.90      0  \n27088  -0.032292  0.199587 -0.832829  0.119214  0.206759  560.84      0  \n51482  -0.723647  0.091818  1.017875 -0.046565  0.017560  112.18      0  \n187036 -0.000273  0.156483  0.573231  0.674625  0.074159   10.62      0  \n242928  0.757645 -0.130722  0.385287 -0.081673 -0.033003  188.00      0  \n\n[5 rows x 31 columns]"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "new_dataset.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1    492\n0    492\nName: Class, dtype: int64"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "new_dataset['Class'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>93133.477642</td>\n      <td>-0.010248</td>\n      <td>-0.056799</td>\n      <td>0.018271</td>\n      <td>0.019108</td>\n      <td>-0.133191</td>\n      <td>-0.103297</td>\n      <td>0.052588</td>\n      <td>-0.019122</td>\n      <td>0.024058</td>\n      <td>...</td>\n      <td>-0.013080</td>\n      <td>-0.000033</td>\n      <td>0.050198</td>\n      <td>-0.001547</td>\n      <td>0.001625</td>\n      <td>-0.009504</td>\n      <td>0.007600</td>\n      <td>-0.029829</td>\n      <td>0.007378</td>\n      <td>100.909675</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80746.806911</td>\n      <td>-4.771948</td>\n      <td>3.623778</td>\n      <td>-7.033281</td>\n      <td>4.542029</td>\n      <td>-3.151225</td>\n      <td>-1.397737</td>\n      <td>-5.568731</td>\n      <td>0.570636</td>\n      <td>-2.581123</td>\n      <td>...</td>\n      <td>0.372319</td>\n      <td>0.713588</td>\n      <td>0.014049</td>\n      <td>-0.040308</td>\n      <td>-0.105130</td>\n      <td>0.041449</td>\n      <td>0.051648</td>\n      <td>0.170575</td>\n      <td>0.075667</td>\n      <td>122.211321</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 30 columns</p>\n</div>",
                        "text/plain": "               Time        V1        V2        V3        V4        V5  \\\nClass                                                                   \n0      93133.477642 -0.010248 -0.056799  0.018271  0.019108 -0.133191   \n1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n\n             V6        V7        V8        V9  ...       V20       V21  \\\nClass                                          ...                       \n0     -0.103297  0.052588 -0.019122  0.024058  ... -0.013080 -0.000033   \n1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n\n            V22       V23       V24       V25       V26       V27       V28  \\\nClass                                                                         \n0      0.050198 -0.001547  0.001625 -0.009504  0.007600 -0.029829  0.007378   \n1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n\n           Amount  \nClass              \n0      100.909675  \n1      122.211321  \n\n[2 rows x 30 columns]"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "new_dataset.groupby('Class').mean()"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "X = new_dataset.drop(columns='Class', axis=1)\nY = new_dataset['Class']"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "            Time        V1        V2        V3        V4        V5        V6  \\\n180032  124348.0  2.063427  0.085239 -2.717546  0.291824  0.978255 -0.775750   \n283256  171474.0 -0.356063  1.255688 -0.535197 -0.629285  0.816733 -0.714564   \n189269  128327.0 -0.780566  0.664675  1.832374  0.647674  1.123108  2.229341   \n19172    30064.0 -2.132175 -2.670250  0.778709 -0.959164  1.189428 -2.230567   \n126261   77970.0 -0.767265  0.460149  2.627017 -1.872647 -0.688661 -0.940017   \n...          ...       ...       ...       ...       ...       ...       ...   \n279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n\n              V7        V8        V9  ...       V20       V21       V22  \\\n180032  0.501467 -0.180248  0.130887  ... -0.242444  0.050044  0.179758   \n283256  0.987774 -0.167297  0.344233  ...  0.252972  0.296516  1.249386   \n189269  0.474599  0.543709 -0.005425  ...  0.181428 -0.515526 -0.948277   \n19172  -0.731199  0.182763 -0.925460  ...  0.960809  0.580102  0.717421   \n126261  0.462549 -0.108100  1.454191  ...  0.050812 -0.047347  0.282201   \n...          ...       ...       ...  ...       ...       ...       ...   \n279863 -0.882850  0.697211 -2.064945  ...  1.252967  0.778584 -0.319189   \n280143 -1.413170  0.248525 -1.127396  ...  0.226138  0.370612  0.028234   \n280149 -2.234739  1.210158 -0.652250  ...  0.247968  0.751826  0.834108   \n281144 -2.208002  1.058733 -1.632333  ...  0.306271  0.583276 -0.269209   \n281674  0.223050 -0.068384  0.577829  ... -0.017652 -0.164350 -0.295135   \n\n             V23       V24       V25       V26       V27       V28  Amount  \n180032 -0.060364  0.225957  0.338667  0.693408 -0.119259 -0.067486   18.00  \n283256 -0.099923  0.639493 -0.664927 -0.233804  0.732638  0.444570    7.95  \n189269 -0.164671 -1.710664  0.207010 -0.699375  0.230199 -0.105916   23.10  \n19172   0.700893  0.505338 -0.189663 -0.360148  0.242405  0.279173  171.75  \n126261 -0.355958  0.710415  0.486787 -0.804267  0.188046 -0.082773    1.00  \n...          ...       ...       ...       ...       ...       ...     ...  \n279863  0.639419 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00  \n280143 -0.145640 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76  \n280149  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89  \n281144 -0.456108 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00  \n281674 -0.072173 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53  \n\n[984 rows x 30 columns]\n"
                }
            ],
            "source": "print(X)"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "180032    0\n283256    0\n189269    0\n19172     0\n126261    0\n         ..\n279863    1\n280143    1\n280149    1\n281144    1\n281674    1\nName: Class, Length: 984, dtype: int64\n"
                }
            ],
            "source": "print(Y)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Split the data into Training data & Testing Data"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(984, 30) (787, 30) (197, 30)\n"
                }
            ],
            "source": "print(X.shape, X_train.shape, X_test.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model Training<br>\n\n### Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": "model = LogisticRegression(solver='lbfgs', max_iter=400)"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "LogisticRegression(max_iter=400)"
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model.fit(X_train, Y_train)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Model Evaluation\n\nAccuracy Score"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": "# accuracy on training data\nX_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on Training data :  0.9479034307496823\n"
                }
            ],
            "source": "print('Accuracy on Training data : ', training_data_accuracy)"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": "# accuracy on test data\nX_test_prediction = model.predict(X_test)\ntest_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy score on Test Data :  0.9238578680203046\n"
                }
            ],
            "source": "print('Accuracy score on Test Data : ', test_data_accuracy)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Tuning hyperparameter C"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.9s finished\n"
                },
                {
                    "data": {
                        "text/plain": "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n             estimator=LogisticRegression(max_iter=400),\n             param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000]},\n             return_train_score=True, scoring='roc_auc', verbose=1)"
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Creating KFold object with 5 splits\nfolds = KFold(n_splits=5, shuffle=True, random_state=4)\n\n# Specify params\nparams = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n\n# Specifing score as recall as we are more focused on acheiving the higher sensitivity than the accuracy\nmodel_cv = GridSearchCV(estimator = LogisticRegression(solver='lbfgs', max_iter=400),\n                        param_grid = params, \n                        scoring= 'roc_auc', \n                        cv = folds, \n                        verbose = 1,\n                        return_train_score=True) \n\n# Fit the model\nmodel_cv.fit(X_train, Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " The highest test roc_auc is 0.9685778918919741 at C = 1000\n"
                }
            ],
            "source": "# Best score with best C\nbest_score = model_cv.best_score_\nbest_C = model_cv.best_params_['C']\n\nprint(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": "# Instantiate the model with best C\nlogistic_imb = LogisticRegression(solver='lbfgs', max_iter=400,C=1000)"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": "# Fit the model on the train set\nlogistic_imb_model = logistic_imb.fit(X_train, Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [],
            "source": "# Predictions on the train set\ny_train_pred = logistic_imb_model.predict(X_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95       393\n           1       0.97      0.93      0.95       394\n\n    accuracy                           0.95       787\n   macro avg       0.95      0.95      0.95       787\nweighted avg       0.95      0.95      0.95       787\n\n"
                }
            ],
            "source": "# classification_report\nprint(classification_report(Y_train, y_train_pred))"
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": "# Prediction on the test set\ny_test_pred = logistic_imb_model.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95        99\n           1       0.97      0.93      0.95        98\n\n    accuracy                           0.95       197\n   macro avg       0.95      0.95      0.95       197\nweighted avg       0.95      0.95      0.95       197\n\n"
                }
            ],
            "source": "# classification_report\nprint(classification_report(Y_test, y_test_pred))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Decision Tree Classifier"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.2s finished\n"
                },
                {
                    "data": {
                        "text/plain": "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n             param_grid={'max_depth': range(5, 15, 5),\n                         'min_samples_leaf': range(50, 150, 50),\n                         'min_samples_split': range(50, 150, 50)},\n             scoring='roc_auc', verbose=1)"
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Create the parameter grid \nparam_grid = {\n    'max_depth': range(5, 15, 5),\n    'min_samples_leaf': range(50, 150, 50),\n    'min_samples_split': range(50, 150, 50),\n}\n\n\n# Instantiate the grid search model\ndtree = DecisionTreeClassifier()\n\ngrid_search = GridSearchCV(estimator = dtree, \n                           param_grid = param_grid, \n                           scoring= 'roc_auc',\n                           cv = 3, \n                           verbose = 1)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train,Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Best roc_auc:- 0.9633100423264166\nDecisionTreeClassifier(max_depth=5, min_samples_leaf=50, min_samples_split=100)\n"
                }
            ],
            "source": "# Printing the optimal sensitivity score and hyperparameters\nprint(\"Best roc_auc:-\", grid_search.best_score_)\nprint(grid_search.best_estimator_)"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "DecisionTreeClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=100,\n                       random_state=100)"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Model with optimal hyperparameters\ndt_imb_model = DecisionTreeClassifier(criterion = \"gini\", \n                                  random_state = 100,\n                                  max_depth=10, \n                                  min_samples_leaf=50,\n                                  min_samples_split=100)\n\ndt_imb_model.fit(X_train, Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "# Predictions on the train set\ny_train_pred = dt_imb_model.predict(X_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.88      0.99      0.93       393\n           1       0.99      0.86      0.92       394\n\n    accuracy                           0.93       787\n   macro avg       0.93      0.93      0.92       787\nweighted avg       0.93      0.93      0.92       787\n\n"
                }
            ],
            "source": "# classification_report\nprint(classification_report(Y_train, y_train_pred))"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": "# Predictions on the test set\ny_test_pred = dt_imb_model.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.84      0.99      0.91        99\n           1       0.99      0.81      0.89        98\n\n    accuracy                           0.90       197\n   macro avg       0.91      0.90      0.90       197\nweighted avg       0.91      0.90      0.90       197\n\n"
                }
            ],
            "source": "# classification_report\nprint(classification_report(Y_test, y_test_pred))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## RandomForest Classifier"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    9.3s finished\n"
                },
                {
                    "data": {
                        "text/plain": "GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n             param_grid={'max_depth': range(5, 10, 5), 'max_features': [10, 20],\n                         'min_samples_leaf': range(50, 150, 50),\n                         'min_samples_split': range(50, 150, 50),\n                         'n_estimators': [100, 200, 300]},\n             return_train_score=True, verbose=1)"
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "param_grid = {\n    'max_depth': range(5,10,5),\n    'min_samples_leaf': range(50, 150, 50),\n    'min_samples_split': range(50, 150, 50),\n    'n_estimators': [100,200,300], \n    'max_features': [10, 20]\n}\n# Create a based model\nrf = RandomForestClassifier()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, \n                           param_grid = param_grid, \n                           cv = 2,\n                           n_jobs = -1,\n                           verbose = 1, \n                           return_train_score=True)\n\n# Fit the model\ngrid_search.fit(X_train, Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "We can get accuracy of 0.9352081476601956 using {'max_depth': 5, 'max_features': 10, 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 100}\n"
                }
            ],
            "source": "# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "# model with the best hyperparameters\n\nrfc_imb_model = RandomForestClassifier(bootstrap=True,\n                             max_depth=5,\n                             min_samples_leaf=50, \n                             min_samples_split=5,\n                             max_features=10,\n                             n_estimators=100)"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "RandomForestClassifier(max_depth=5, max_features=10, min_samples_leaf=50,\n                       min_samples_split=5)"
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "rfc_imb_model.fit(X_train, Y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": "\n# Predictions on the train set\ny_train_pred = rfc_imb_model.predict(X_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.99      0.94       393\n           1       0.99      0.89      0.94       394\n\n    accuracy                           0.94       787\n   macro avg       0.95      0.94      0.94       787\nweighted avg       0.95      0.94      0.94       787\n\n"
                }
            ],
            "source": "# classification_report\nprint(classification_report(Y_train, y_train_pred))"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": "# Predictions on the test set\ny_test_pred = rfc_imb_model.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.87      0.98      0.92        99\n           1       0.98      0.86      0.91        98\n\n    accuracy                           0.92       197\n   macro avg       0.93      0.92      0.92       197\nweighted avg       0.93      0.92      0.92       197\n\n"
                }
            ],
            "source": "# classification_report\nprint(classification_report(Y_test, y_test_pred))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using UnderSampling technique,I tried three models on this data.The three models have performed well in terms of Precision, Recall and F1 Score.<br>But while picking the best model we should consider few things such as whether we have required infrastructure, resources or computational power to run the model or not. For the models such as Random forest we require heavy computational resources and eventually to build that infrastructure the cost of deploying the model increases. On the other hand the simpler model such as Logistic regression requires less computational resources, so the cost of building the model is less.\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "After performing several models, Logistic Regression is the best model for this data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}